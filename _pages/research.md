---
#layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

My research areas include application of Deep Learning techniques to problems in Natural Language Processing, Computer Vision and Speech Recognition. 

**Pose Based Action Recognition using Hierarchical Bidirectional Long Short Term Memory Networks**
We propose an end-to-end pipeline for the task of human action recognition on video sequences using 2D joint trajectories estimated from a pose estimation framework. We use a Hierarchical Bidirectional Long Short Term Memory Network (HBLSTM) to model the spatio-temporal dependencies of the motion by fusing the pose based dense trajectories in a part based hierarchical fashion. 

**Short Term Context-based Fast Multilingual Acoustic Model for Low Resource Languages**
We propose an architecture based on short term contextual temporal features learned on Convolutional Neural Networks (CNNs) with a non-sequential discriminative network for building a multilingual automation speech recognition system. Three low resource Indic languages, Gujarati, Tamil, and Telugu are used ascertain that our proposed architecture trains 5.5x faster and reduces the inference time by a factor of 26 while maintaining word error rates against comparable baseline RNNs. 

**Minimally Supervised Sound Event Detection using a Neural Network**
We propose a sound event detection system that is trained using a minimally annotated data set of single sounds to identify and separate components of polyphonic sounds. The system uses a Feed Forward Neural Network that is pre-trained using an auto-encoder. Single sounds, represented as MFCCs are used to train the network. Polyphonic sounds are preprocessed using Principal Component Analysis and Non-negative Matrix Factorization (NMF) to obtain source separated sounds. Our system was able to achieve reasonable accuracy of source separation and detection with minimal training set. 
